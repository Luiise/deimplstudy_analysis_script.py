#!/usr/bin/python
from __future__ import division

import matplotlib.pyplot as plt
import numpy as np
import pymc3 as pm
import csv
import pandas as pd
from pandas.plotting import table
import seaborn as sns
from pprint import pprint as print
from matplotlib.backends.backend_pdf import PdfPages
import plotly.figure_factory as ff
from scipy.stats import shapiro
from scipy.stats import mannwhitneyu
from statsmodels.stats.power import TTestIndPower

import sqlite3

sns.set(color_codes=True)
from scipy.stats import ttest_ind
import sys

conn = sqlite3.connect('databaseSQLite.sqlite')
cursor = conn.cursor()


# def get_col_vals(df, col1, col2):
#     """
#     Get column values
#     """
#     drug = (101, 100, 102, 104, 102, 97, 105, 105, 98, 101, 100, 123, 105, 103, 100, 95, 102, 106,
#             109, 102, 82, 102, 100, 102, 102, 101, 102, 102, 103, 103, 97, 97, 103, 101, 97, 104,
#             96, 103, 124, 101, 101, 100, 101, 101, 104, 100, 101)
#     placebo = (99, 101, 100, 101, 102, 100, 97, 101, 104, 101, 102, 102, 100, 105, 88, 101, 100,
#                104, 100, 100, 100, 101, 102, 103, 97, 101, 101, 100, 101, 99, 101, 100, 100,
#                101, 100, 99, 101, 100, 102, 99, 100, 99)
#     y1 = np.array(drug)
#     y2 = np.array(placebo)
#
#     return y1, y2
#
#
# def prep_data(df, col1, col2):
#     """
#     Prepare data for pymc3 and return mean mu and sigma
#     """
#
#     drug = (101, 100, 102, 104, 102, 97, 105, 105, 98, 101, 100, 123, 105, 103, 100, 95, 102, 106,
#             109, 102, 82, 102, 100, 102, 102, 101, 102, 102, 103, 103, 97, 97, 103, 101, 97, 104,
#             96, 103, 124, 101, 101, 100, 101, 101, 104, 100, 101)
#     placebo = (99, 101, 100, 101, 102, 100, 97, 101, 104, 101, 102, 102, 100, 105, 88, 101, 100,
#                104, 100, 100, 100, 101, 102, 103, 97, 101, 101, 100, 101, 99, 101, 100, 100,
#                101, 100, 99, 101, 100, 102, 99, 100, 99)
#
#     y1 = np.array(drug)
#     y2 = np.array(placebo)
#
#     # np.r_[a,b] - concat a,b
#     # dataframe:
#     # value  group
#     # 101    drug
#     # 100    drug
#     # ...
#     # 99     placebo
#     # ...
#     # 99     placebo
#     y = pd.DataFrame(dict(value=np.r_[y1, y2],
#                           group=np.r_[[col1] * len(y1),
#                                       [col2] * len(y2)]))
#     mu = y.value.mean()
#     sigma = y.value.std() * 2
#
#     y.hist("value", by="group", figsize=(12, 4))
#     plt.show()
#
#     return y, mu, sigma
#
#
# y, mu, sigma = prep_data([], 'drug', 'placebo')
# y.hist('value', by='group')
#
# # likelihood functions - t-dist because it's less sensitive to outliers compared to the normal distribution
# # y(treat)i∼T(ν,μ1,σ1)
# # y(placebo)i∼T(ν,μ2,σ2)
#
# # Since the means are real-valued, we will apply normal priors on them,
# # and arbitrarily set the hyperparameters to the pooled empirical mean of the data
# # and twice the pooled empirical standard deviation, which applies very diffuse information
# # to these quantities (and importantly, does not favor one or the other a priori).
# # μk∼N(x¯,2s)
#
# μ_m = y.value.mean()
# μ_s = y.value.std() * 2
#
# # group standard deviations to have a Uniform(1,10) prior
# σ_low = 1
# σ_high = 10
#
# with pm.Model() as model:
#     y1, y2 = get_col_vals([], "", "")
#     # priors
#     group1_mean = pm.Normal("group1_mean", mu=μ_m, sd=μ_s)
#     group2_mean = pm.Normal("group2_mean", mu=μ_m, sd=μ_s)
#
#     group1_std = pm.Uniform("group1_std", lower=σ_low, upper=σ_high)
#     group2_std = pm.Uniform("group2_std", lower=σ_low, upper=σ_high)
#
#     """
#         Prior for ν is an exponential (lambda=29) shifted +1.
#         spreads credibility fairly evenly over nearly normal or heavy tailed data;
#         this allocates high prior probability over the regions of the parameter that
#         describe the range from normal to heavy-tailed data under the Student-T distribution.
#         """
#     ν = pm.Exponential('ν_minus_one', 1 / 29.) + 1
#
#     # Since PyMC3 parameterizes the Student-T in terms of precision,
#     # rather than standard deviation, we must transform the standard deviations
#     # before specifying our likelihoods.
#     """
#             Transforming standard deviations to precisions (inverse-variance: 1/variance) before
#             specifying likelihoods.
#             """
#     # precisions inverse-variance
#     λ1 = group1_std ** -2
#     λ2 = group2_std ** -2
#
#     # likelihood
#     group1 = pm.StudentT("drug", nu=ν, mu=group1_mean, lam=λ1, observed=y1)
#     group2 = pm.StudentT("placebo", nu=ν, mu=group2_mean, lam=λ2, observed=y2)
#
# with model:
#     diff_of_means = pm.Deterministic("difference of means", group1_mean - group2_mean)
#     diff_of_stds = pm.Deterministic("difference of stds", group1_std - group2_std)
#
#     """
#        The effect size is the difference in means/pooled estimates of the standard deviation.
#        The Deterministic class represents variables whose values are completely determined
#        by the values of their parents.
#        """
#     effect_size = pm.Deterministic(
#         "effect size", diff_of_means / np.sqrt((group1_std ** 2 + group2_std ** 2) / 2)
#     )
#     print("effect size AI: ")
#     print(effect_size)
#
# with model:
#     trace = pm.sample(2000, cores=1)
#
# pm.plot_posterior(
#     trace,
#     var_names=["group1_mean", "group2_mean", "group1_std", "group2_std", "ν_minus_one"],
#     color="#87ceeb",
# )
# plt.show()
#
# pm.plot_posterior(
#     trace,
#     var_names=["difference of means", "difference of stds", "effect size"],
#     ref_val=0,
#     color="#87ceeb",
# )
#
# plt.show()


# https://github.com/neilernst/cliffsDelta/blob/master/cliffsDelta.py
def cliffs_delta(lst1, lst2, **dull):
    """Returns delta and true if there are more than 'dull' differences"""
    if not dull:
        dull = {'small': 0.147, 'medium': 0.33, 'large': 0.474}  # effect sizes from (Hess and Kromrey, 2004)
    m, n = len(lst1), len(lst2)
    lst2 = sorted(lst2)
    j = more = less = 0
    for repeats, x in runs(sorted(lst1)):
        while j <= (n - 1) and lst2[j] < x:
            j += 1
        more += j * repeats
        while j <= (n - 1) and lst2[j] == x:
            j += 1
        less += (n - j) * repeats
    d = (more - less) / (m * n)
    size = lookup_size(d, dull)
    return d, size


def lookup_size(delta: float, dull: dict) -> str:
    delta = abs(delta)
    if delta < dull['small']:
        return 'negligible'
    if dull['small'] <= delta < dull['medium']:
        return 'small'
    if dull['medium'] <= delta < dull['large']:
        return 'medium'
    if delta >= dull['large']:
        return 'large'


def runs(lst):
    """Iterator, chunks repeated values"""
    for j, two in enumerate(lst):
        if j == 0:
            one, i = two, 0
        if one != two:
            yield j - i, one
            i = j
        one = two
    yield j - i + 1, two


# Small Effect Size: d = 0.2
# Medium Effect Size: d = 0.5
# Large Effect Size: d = 0.8
# a lower value of Cohen’s d indicates the necessity of a larger
# sample size and vice versa
def cohen_d(group1, group2):
    group1 = [x for x in group1 if (np.isnan(x) == False)]
    group2 = [x for x in group2 if (np.isnan(x) == False)]
    n1, n2 = len(group1), len(group2)

    s1, s2 = np.var(group1, ddof=1), np.var(group2, ddof=1)
    # pooled standard deviation
    s = np.sqrt(((n1 - 1) * s1 + (n2 - 1) * s2) / (n1 + n2 - 2))

    u1, u2 = np.mean(group1), np.mean(group2)

    return (u1 - u2) / s


solution = ["yes", "no", "no", "no", "no", "yes", "yes", "no", "no"]


class Task:
    def __init__(self, task_id, times_tg=None, times_cg=None, answers_tg=None,
                 answers_cg=None, time_cg_novices=None, time_tg_novices=None, answers_cg_novices=None,
                 answers_tg_novices=None, time_cg_experts=None, time_tg_experts=None, answers_cg_experts=None,
                 answers_tg_experts=None):

        if answers_cg_experts is None:
            self.answers_cg_experts = []
        else:
            self.answers_cg_experts = answers_cg_experts

        if answers_tg_experts is None:
            self.answers_tg_experts = []
        else:
            self.answers_tg_experts = answers_tg_experts

        if time_tg_experts is None:
            self.time_tg_experts = []
        else:
            self.time_tg_experts = time_tg_experts

        if time_tg_experts is None:
            self.time_tg_experts = []
        else:
            self.time_tg_experts = time_tg_experts

        if time_cg_experts is None:
            self.time_cg_experts = []
        else:
            self.time_cg_experts = time_cg_experts

        if answers_cg_novices is None:
            self.answers_cg_novices = []
        else:
            self.answers_cg_novices = answers_cg_novices

        if answers_cg is None:
            self.answers_cg = []
        else:
            self.answers_cg = answers_cg

        if answers_tg_novices is None:
            self.answers_tg_novices = []
        else:
            self.answers_tg_novices = answers_tg_novices

        if time_cg_novices is None:
            self.time_cg_novices = []
        else:
            self.time_cg_novices = time_cg_novices

        if time_tg_novices is None:
            self.time_tg_novices = []
        else:
            self.time_tg_novices = time_tg_novices

        if times_cg is None:
            self.times_cg = []
        else:
            self.times_cg = times_cg

        if answers_tg is None:
            self.answers_tg = []
        else:
            self.answers_tg = answers_tg

        if times_tg is None:
            self.times_tg = []
        else:
            self.times_tg = times_tg

        self.task_Id = task_id

    def get_general_difference_in_time(self):
        return perform_significance_test(tg=self.times_tg, cg=self.times_cg, task_id=self.task_Id)

    def get_general_difference_in_correctness(self):
        return perform_significance_test(tg=self.answers_tg, cg=self.answers_cg, task_id=self.task_Id)

    def get_experts_difference_in_time(self):
        return perform_significance_test(tg=self.time_tg_experts, cg=self.time_cg_experts,task_id=self.task_Id)

    def get_experts_difference_in_correctness(self):
        return perform_significance_test(tg=self.answers_tg_experts, cg=self.answers_cg_experts, task_id=self.task_Id)

    def get_novices_difference_in_time(self):
        return perform_significance_test(tg=self.time_tg_novices, cg=self.time_cg_novices, task_id=self.task_Id)

    def get_novices_difference_in_correctness(self):
        return perform_significance_test(tg=self.answers_tg_novices, cg=self.answers_cg_novices, task_id=self.task_Id)

    def do_descriptive_statistics(self):
        self.__get_descriptive_statistics(self, cg=self.times_cg, tg=self.times_tg, filename="rq1",
                                          title_hist="Time needed", xlabel_hist="Time in sec",
                                          ylabel_hist="Number of participants")
        self.__get_descriptive_statistics(self, cg=self.answers_cg, tg=self.answers_tg, filename="rq2",
                                          title_hist="Correctly solved tasks",
                                          xlabel_hist="Number of correctly answered tasks",
                                          ylabel_hist="Number of participants")
        self.__get_descriptive_statistics(self, cg=self.time_cg_novices, tg=self.time_tg_novices,
                                          filename="rq3_rq1_novices",
                                          title_hist="Time needed", xlabel_hist="Time in sec",
                                          ylabel_hist="Number of participants")
        self.__get_descriptive_statistics(self, cg=self.time_cg_experts, tg=self.time_tg_experts,
                                          filename="rq3_rq1_experts",
                                          title_hist="Time needed", xlabel_hist="Time in sec",
                                          ylabel_hist="Number of participants")
        self.__get_descriptive_statistics(self, cg=self.answers_cg_novices, tg=self.answers_tg_novices,
                                          filename="rq3_rq2_novices",
                                          title_hist="Correctly solved tasks by novices",
                                          xlabel_hist="Number of correctly answered tasks",
                                          ylabel_hist="Number of participants")
        self.__get_descriptive_statistics(self, cg=self.answers_cg_experts, tg=self.answers_tg_experts,
                                          filename="rq3_rq2_experts",
                                          title_hist="Correctly solved tasks",
                                          xlabel_hist="Number of correctly answered tasks",
                                          ylabel_hist="Number of participants")

    def __get_descriptive_statistics(self, cg=None, tg=None, filename="", title_hist="", xlabel_hist="",
                                     ylabel_hist=""):
        self.__calculate_statistics_summary(filename=filename, cg=cg, tg=tg)
        self.__calculate_histogram(cg=cg, tg=tg, filename=filename, xlabel=xlabel_hist, ylable=ylabel_hist,
                                   title=title_hist)
        pass

    def __get_filename(self, filename, extension):
        return "task_" + self.task_Id + "_" + filename + extension

    def __calculate_statistics_summary(self, filename="", cg=None, tg=None):
        filename_final = self.__get_filename(filename=filename, extension=".csv")
        summary_statistics = get_statistics_summary(cg=cg, tg=tg)
        summary_statistics.to_csv(filename_final)
        pass

    def __calculate_histogram(self, cg, tg, filename, xlabel, ylable, title):
        filename_final = self.__get_filename(filename=filename, extension=".png")
        get_histogram(cg=cg, tg=tg, filename=filename_final, xlabel=xlabel, ylable=ylable, title=title)
        pass


def get_init_tasks(task_solutions):
    tasks = []
    for i in range(len(task_solutions)):
        tasks.append(Task(task_id=(i + 1)))
    return tasks


def get_task_solutions():
    return {
        "1": "yes",
        "2": "no",
        "3": "no",
        "4": "no",
        "5": "no",
        "6": "yes",
        "7": "yes",
        "8": "no",
        "9": "no"
    }
    # return {
    #     "1": "no",
    #     "2": "yes",
    #     "3": "yes",
    #     "4": "yes"
    # }


tasks = get_init_tasks(task_solutions=get_task_solutions())


class ParticipantData:
    # TODO: only consider those with experience SQL, Python >1 (store those sessionIDs who do not in an array)
    def __init__(self, sessionID, demographics_id, treatment_group, experience_ROR, answers, times):
        self.sessionID = sessionID
        self.demographics_id = demographics_id
        self.treatment_group = treatment_group
        self.experience_ROR = experience_ROR
        self.answers = answers
        self.times = times

    def get_avg_time(self):
        return np.mean(self.times)

    def get_correct_answer_score(self):
        score = 0
        zip_answers_solution = zip(solution, self.answers)
        for answer_tuple in zip_answers_solution:
            if answer_tuple[0] == answer_tuple[1]:
                score += 1
        return score


def separate_cg_tg(all_participants):
    tg = []
    cg = []
    if all_participants is not None:
        for participant in all_participants:
            if participant.treatment_group == 1:
                tg.append(participant)
            else:
                cg.append(participant)

    return tg, cg


def get_times_as_array(participants):
    times = []
    for participant in participants:
        times.append(participant.get_avg_time())
    return times


def get_rq1_data(all_participants):
    tg, cg = separate_cg_tg(all_participants)
    tg_times = get_times_as_array(tg)
    cg_times = get_times_as_array(cg)
    return tg_times, cg_times


def get_all_answer_scores_as_array(participants):
    avg_answers = []
    for participant in participants:
        avg_answers.append(participant.get_correct_answer_score())
    return avg_answers


def get_rq2_data(all_participants):
    tg, cg = separate_cg_tg(all_participants)
    tg_answer_scores = get_all_answer_scores_as_array(tg)
    cg_answer_scores = get_all_answer_scores_as_array(cg)
    return tg_answer_scores, cg_answer_scores


def separate_experts_novice(all_participants):
    experts = []
    novice = []
    for participant in all_participants:
        if participant.experience_ROR < 1:
            novice.append(participant)
        else:
            experts.append(participant)

    return experts, novice
    pass


def get_rq3_data(all_participants):
    experts, novices = separate_experts_novice(all_participants)
    rq3_novices_rq1_tg, rq3_novices_rq1_cg = get_rq1_data(novices)
    rq3_novices_rq2_tg, rq3_novices_rq2_cg = get_rq2_data(novices)
    rq3_experts_rq1_tg, rq3_experts_rq1_cg = get_rq1_data(experts)
    rq3_experts_rq2_tg, rq3_experts_rq2_cg = get_rq2_data(experts)

    return rq3_novices_rq1_tg, rq3_novices_rq1_cg, rq3_novices_rq2_tg, rq3_novices_rq2_cg, \
           rq3_experts_rq1_tg, rq3_experts_rq1_cg, rq3_experts_rq2_tg, rq3_experts_rq2_cg


def get_dempgraphics_join_question_by_sessionID_string():
    return 'SELECT Demographics.id as demographics_id, ' \
           'Demographics.sessionID as sessionID, ' \
           'Demographics.treatment_group as treatment_group, ' \
           'Demographics.experience_ROR as experience_ROR, ' \
           'Question.taskID as taskID, ' \
           'Question.questionID as questionID, ' \
           'Question.answer as answer, ' \
           'Question.time as time ' \
           'FROM Demographics INNER JOIN Question ON ' \
           'Demographics.sessionID = Question.sessionID ' \
           'WHERE Demographics.sessionID = ? ' \
           'ORDER BY questionID'
    pass


def get_participants_data():
    participants = []
    select_all_sessionIDs = "SELECT DISTINCT sessionID from Question"
    join_Demographics_Question = get_dempgraphics_join_question_by_sessionID_string()

    for row in cursor.execute(select_all_sessionIDs).fetchall():
        treatment_group = 0
        answers = []
        times = []
        demographics_id = 0
        experience_ROR = 0
        sessionID = row

        for row2 in cursor.execute(join_Demographics_Question, row):
            demographics_id = row2[0]
            treatment_group = row2[2]
            experience_ROR = row2[3]
            answers.append(row2[6])
            times.append(row2[7])

        new_participant = ParticipantData(sessionID, demographics_id, treatment_group, experience_ROR, answers, times)
        participants.append(new_participant)
        # print("answer score: ")
        # print(new_participant.get_correct_answer_score())
        # print("avg time needed: ")
        # print(new_participant.get_avg_time())
        # print("")
    return participants


def get_statistics_summary(tg, cg):
    # Create a Dictionary of series
    d = {'treatment_group': pd.Series(tg),
         'control_group': pd.Series(cg)
         }

    # Create a DataFrame
    df = pd.DataFrame(d)
    summary = pd.concat([df.describe(), pd.DataFrame(df.median(), columns=["Median"]).T])

    return summary


def is_normal(data):
    stat, p = shapiro(data)
    print('Statistics=%.3f, p=%.3f' % (stat, p))

    alpha = 0.05
    if p > alpha:
        print('Sample looks Gaussian (fail to reject H0)')
        return True
    else:
        print('Sample does not look Gaussian (reject H0)')
        return False
    pass


def test_result_summary(stat, p, alpha=0.05, task_id=0):
    is_different = False
    if p > alpha:
        print('Same distribution (fail to reject H0); no difference in response time between the groups')
        is_different = False
    else:
        print('Different distribution (reject H0); there is a difference in response time between the groups')
        is_different = True
        return True
    pass
    return {"task_id": task_id, "stat": stat, "p": p, "is_different": is_different}
    pass


def perform_mann_whitney_u_test(data1, data2, task_id=0):
    # Fail to Reject H0: Sample distributions are equal.
    # Reject H0: Sample distributions are not equal.

    stat, p = mannwhitneyu(x=data1, y=data2, alternative="less")
    print('Statistics=%.3f, p=%.3f' % (stat, p))
    # interpret
    return test_result_summary(stat=stat, p=p, task_id=task_id)
    # alpha = 0.05
    # if p > alpha:
    #     print('Same distribution (fail to reject H0); no difference in response time between the groups')
    #     return False
    # else:
    #     print('Different distribution (reject H0); there is a difference in response time between the groups')
    #     return True
    pass


def perform_student_t_test(data1, data2, task_id=0):
    stat, p = ttest_ind(a=data1, b=data2, alternative="less")
    print('t=%.3f, p=%.3f' % (stat, p))

    return test_result_summary(stat=stat, p=p, task_id=task_id)
    # alpha = 0.05
    # if p > alpha:
    #     print('Accept null hypothesis that the means are equal.')
    #     return False
    # else:
    #     print('Reject the null hypothesis that the means are equal.')
    #     return True
    pass


def perform_significance_test(tg, cg, task_id=0):
    overall = tg + cg
    is_normal_distributed = is_normal(overall)

    if is_normal_distributed:
        return perform_student_t_test(tg, cg, task_id)
    else:
        return perform_mann_whitney_u_test(tg, cg, task_id)

    pass


def get_histogram(tg, cg, title, xlabel="", ylable='Density', filename="hist.png"):
    n_bins = 20

    sns.distplot(tg, kde=False, label='Treatment Group', bins=n_bins)
    sns.distplot(cg, kde=False, label='Control Group', bins=n_bins)

    # Plot formatting
    plt.legend(prop={'size': 12})
    plt.title(title)
    plt.xlabel(xlabel)
    plt.ylabel(ylable)
    plt.savefig(filename)
    plt.show()

    pass


def get_all_histograms(rq1_tg, rq1_cg, rq2_tg, rq2_cg, rq3_novices_rq1_cg, rq3_novices_rq1_tg, rq3_novices_rq2_cg,
                       rq3_novices_rq2_tg, rq3_experts_rq1_cg, rq3_experts_rq1_tg, rq3_experts_rq2_cg,
                       rq3_experts_rq2_tg):
    get_histogram(rq1_tg, rq1_cg, title="RQ1", xlabel="Time in seconds", ylable="Number of Participants",
                  filename="hist_rq1.png")

    get_histogram(rq2_tg, rq2_cg, title="RQ2", xlabel="Correct answers", ylable="Number of Participants",
                  filename="hist_rq2.png")

    get_histogram(rq3_novices_rq1_tg, rq3_novices_rq1_cg, title="RQ3 Time spent novice", xlabel="Time in seconds",
                  ylable="Number of Participants",
                  filename="hist_rq3_rq1_novice.png")

    get_histogram(rq3_novices_rq2_tg, rq3_novices_rq2_cg, title="RQ3 Correct answers novice", xlabel="Correct answers",
                  ylable="Number of Participants",
                  filename="hist_rq3_rq2_novice.png")

    get_histogram(rq3_experts_rq1_tg, rq3_experts_rq1_cg, title="RQ3 Time spent experts", xlabel="Time in seconds",
                  ylable="Number of Participants",
                  filename="hist_rq3_rq1_experts.png")

    get_histogram(rq3_experts_rq2_tg, rq3_experts_rq2_cg, title="RQ3 Correct answers experts", xlabel="Correct answers",
                  ylable="Number of Participants",
                  filename="hist_rq3_rq2_experts.png")

    pass


def calc_statistics(rq1_tg, rq1_cg, rq2_tg, rq2_cg, rq3_novices_rq1_cg, rq3_novices_rq1_tg, rq3_novices_rq2_cg,
                    rq3_novices_rq2_tg, rq3_experts_rq1_cg, rq3_experts_rq1_tg, rq3_experts_rq2_cg, rq3_experts_rq2_tg):
    summary_statistics_rq1 = get_statistics_summary(rq1_tg, rq1_cg)
    summary_statistics_rq2 = get_statistics_summary(rq2_tg, rq2_cg)
    summary_statistics_rq3_novices_rq1 = get_statistics_summary(rq3_novices_rq1_cg, rq3_novices_rq1_tg)
    summary_statistics_rq3_novices_rq2 = get_statistics_summary(rq3_novices_rq2_cg, rq3_novices_rq2_tg)
    summary_statistics_rq3_experts_rq1 = get_statistics_summary(rq3_experts_rq1_cg, rq3_experts_rq1_tg)
    summary_statistics_rq3_experts_rq2 = get_statistics_summary(rq3_experts_rq2_cg, rq3_experts_rq2_tg)

    # get statistics as csv
    summary_statistics_rq1.to_csv("summary_statistics_rq1.csv")
    summary_statistics_rq2.to_csv("summary_statistics_rq2.csv")
    summary_statistics_rq3_novices_rq1.to_csv("summary_statistics_rq3_novices_rq1.csv")
    summary_statistics_rq3_novices_rq2.to_csv("summary_statistics_rq3_novices_rq2.csv")
    summary_statistics_rq3_experts_rq1.to_csv("summary_statistics_rq3_experts_rq1.csv")
    summary_statistics_rq3_experts_rq2.to_csv("summary_statistics_rq3_experts_rq2.csv")

    # get histograms
    get_all_histograms(rq1_tg, rq1_cg, rq2_tg, rq2_cg, rq3_novices_rq1_cg, rq3_novices_rq1_tg, rq3_novices_rq2_cg,
                       rq3_novices_rq2_tg, rq3_experts_rq1_cg, rq3_experts_rq1_tg, rq3_experts_rq2_cg,
                       rq3_experts_rq2_tg)

    pass


def calc_sample_size(effect):
    alpha = 0.05
    power = 0.4

    analysis = TTestIndPower()
    result = analysis.solve_power(effect, power=power, nobs1=None, ratio=1.0, alpha=alpha)
    print('Sample Size: %.3f' % result)
    return result


def calc_effect_size(tg, cg):
    overall = tg + cg
    is_normal_distributed = is_normal(overall)

    if is_normal_distributed:
        return cohen_d(tg, cg)
    else:
        return cliffs_delta(tg, cg)

    pass


def get_sample_size(tg, cg):
    effect = calc_effect_size(tg, cg)
    sample_size = calc_sample_size(effect)
    return sample_size


def write_to_csv(results, filename):
    with open(filename, 'w', ) as csvfile:
        writer = csv.writer(csvfile)
        writer.writerow(['Task Id', 'T-Statistics', "P-Value", "Is Significant Different"])
        for result in results:
            writer.writerow([result['task_id'], result['stat'], result['p'], result['is_different']])
    pass


def perform_rq1_for_each_task():
    test_results = []
    for task in tasks:
        test_results.append(task.get_general_difference_in_time())
    write_to_csv(results=test_results, filename="test_results_general_difference_in_time.csv")
    pass

def perform_rq2_for_each_task():
    test_results = []
    for task in tasks:
        test_results.append(task.get_experts_difference_in_correctness())
    write_to_csv(results=test_results, filename="test_results_general_difference_in_correctness.csv")
    pass

def init_all_tasks():
    sql_query = "select treatment_group, experience_ROR, answer, time, questionID, D.sessionID " \
                "from Question INNER JOIN Demographics D on Question.sessionID = D.sessionID  " \
                "where questionID = ?"

    qId = [1]
    for i in range(len(tasks)):
        for row in cursor.execute(sql_query, qId):
            # case cg
            if row[0] == 0:
                tasks[qId[0] - 1].answers_cg.append(row[2])
                tasks[qId[0] - 1].times_cg.append(row[3])
                # case experts
                if row[1] >= 1:
                    tasks[qId[0] - 1].answers_cg_experts.append(row[2])
                    tasks[qId[0] - 1].time_cg_experts.append(row[3])
                else:  # case novices
                    tasks[qId[0] - 1].answers_cg_novices.append(row[2])
                    tasks[qId[0] - 1].time_cg_novices.append(row[3])
            else:  # case tg
                tasks[qId[0] - 1].answers_tg.append(row[2])
                tasks[qId[0] - 1].times_tg.append(row[3])
                if row[1] >= 1:  # experts
                    tasks[qId[0] - 1].answers_tg_experts.append(row[2])
                    tasks[qId[0] - 1].time_tg_experts.append(row[3])
                else:  # novices
                    tasks[qId[0] - 1].answers_tg_novices.append(row[2])
                    tasks[qId[0] - 1].time_tg_novices.append(row[3])

        qId[0] = qId[0] + 1

    pass





def analysis():
    # get data
    all_participants = get_participants_data()
    rq1_tg, rq1_cg = get_rq1_data(all_participants)
    rq2_tg, rq2_cg = get_rq2_data(all_participants)
    rq3_novices_rq1_tg, rq3_novices_rq1_cg, rq3_novices_rq2_tg, rq3_novices_rq2_cg, \
    rq3_experts_rq1_tg, rq3_experts_rq1_cg, rq3_experts_rq2_tg, rq3_experts_rq2_cg = get_rq3_data(all_participants)

    init_all_tasks()

    perform_rq1_for_each_task()

    perform_rq2_for_each_task()

    difference_in_time = perform_significance_test(rq1_tg, rq1_cg)
    difference_in_correctness = perform_significance_test(rq2_tg, rq2_cg)

    difference_in_time_novice = perform_significance_test(rq3_novices_rq1_tg, rq3_novices_rq1_cg)
    difference_in_time_experts = perform_significance_test(rq3_experts_rq1_tg, rq3_experts_rq1_cg)
    difference_in_correctness_novice = perform_significance_test(rq3_novices_rq2_tg, rq3_novices_rq2_cg)
    difference_in_correctness_experts = perform_significance_test(rq3_experts_rq2_tg, rq3_experts_rq2_cg)

    # get statistics
    calc_statistics(rq1_tg, rq1_cg, rq2_tg, rq2_cg, rq3_novices_rq1_cg, rq3_novices_rq1_tg, rq3_novices_rq2_cg,
                    rq3_novices_rq2_tg, rq3_experts_rq1_cg, rq3_experts_rq1_tg, rq3_experts_rq2_cg, rq3_experts_rq2_tg)

    sample_size_rq1 = get_sample_size(rq1_tg, rq1_cg)
    sample_size_rq2 = get_sample_size(rq2_tg, rq2_cg)
    sample_size_rq3_novices_rq1 = get_sample_size(rq3_novices_rq1_tg, rq3_novices_rq1_cg)
    sample_size_rq3_novices_rq2 = get_sample_size(rq3_novices_rq2_tg, rq3_novices_rq2_cg)
    sample_size_rq3_experst_rq1 = get_sample_size(rq3_experts_rq1_tg, rq3_experts_rq1_cg)
    sample_size_rq3_experst_rq2 = get_sample_size(rq3_experts_rq2_tg, rq3_experts_rq2_cg)


analysis()

# if __name__ == '__main__':
#     conn = sqlite3.connect('surveyDa/ta.sqlite')
#     table = pd.read_sql_query("SELECT * from Demographics", conn)
#     print(table)
#     cursor = conn.cursor()
#     print(cursor.execute("""SELECT * FROM sqlite_master;""").fetchall())
